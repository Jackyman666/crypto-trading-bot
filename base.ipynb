{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "5137cad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting plotly\n",
      "  Downloading plotly-6.3.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting narwhals>=1.15.1 (from plotly)\n",
      "  Downloading narwhals-2.10.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging in /Users/jack/Desktop/DG/FaceRecognition/.conda/lib/python3.11/site-packages (from plotly) (23.2)\n",
      "Downloading plotly-6.3.1-py3-none-any.whl (9.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading narwhals-2.10.1-py3-none-any.whl (419 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m419.5/419.5 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: narwhals, plotly\n",
      "Successfully installed narwhals-2.10.1 plotly-6.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas_ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
=======
   "execution_count": 25,
>>>>>>> 314ba48baf096f400eac9c1b3916dadb6b4d4b74
   "id": "377d8d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install missing package in the notebook environment\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "840d77d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_BTC = pd.read_csv('Data/1hr/BTCUSDT_1h.csv')\n",
    "df_DOGE = pd.read_csv('Data/1hr/DOGEUSDT_1h.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007aeaac",
   "metadata": {},
   "source": [
    "# Trend Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd6ff6f",
   "metadata": {},
   "source": [
    "### Calculate SMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56b6020b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_SMA20(df, column_name='close', period = 20):\n",
    "\n",
    "    return df[column_name].rolling(window=period).mean()\n",
    "\n",
    "def calculate_SMA50(df, column_name='close', period = 50):\n",
    "    \n",
    "    return df[column_name].rolling(window=period).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b488fbc4",
   "metadata": {},
   "source": [
    "### Calculate EMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc24fd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_EMA20(df, column_name: str = 'close', period: int = 20):\n",
    "\n",
    "    return df[column_name].ewm(span=period, adjust=False).mean()\n",
    "\n",
    "def calculate_EMA50(df, column_name: str = 'close', period: int = 50):\n",
    "\n",
    "    return df[column_name].ewm(span=period, adjust=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "016058b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       timestamp       open       high        low      close  \\\n",
      "0      2020-01-01 00:00:00+00:00    7195.24    7196.25    7175.46    7177.02   \n",
      "1      2020-01-01 01:00:00+00:00    7176.47    7230.00    7175.71    7216.27   \n",
      "2      2020-01-01 02:00:00+00:00    7215.52    7244.87    7211.41    7242.85   \n",
      "3      2020-01-01 03:00:00+00:00    7242.66    7245.00    7220.00    7225.01   \n",
      "4      2020-01-01 04:00:00+00:00    7225.00    7230.00    7215.03    7217.27   \n",
      "...                          ...        ...        ...        ...        ...   \n",
      "51219  2025-11-05 11:00:00+00:00  101401.97  102110.48  101381.68  102070.61   \n",
      "51220  2025-11-05 12:00:00+00:00  102070.62  102800.71  101916.77  102673.35   \n",
      "51221  2025-11-05 13:00:00+00:00  102673.34  103253.39  102291.82  102985.91   \n",
      "51222  2025-11-05 14:00:00+00:00  102985.90  103470.00  102169.06  103202.30   \n",
      "51223  2025-11-05 15:00:00+00:00  103202.30  103441.10  102829.51  103046.68   \n",
      "\n",
      "            volume       SMA_20       SMA_50         EMA_20         EMA_50  \n",
      "0       511.814901          NaN          NaN    7177.020000    7177.020000  \n",
      "1       883.052603          NaN          NaN    7180.758095    7178.559216  \n",
      "2       655.156809          NaN          NaN    7186.671610    7181.080423  \n",
      "3       783.724867          NaN          NaN    7190.322885    7182.803151  \n",
      "4       467.812578          NaN          NaN    7192.889277    7184.154793  \n",
      "...            ...          ...          ...            ...            ...  \n",
      "51219   887.620470  101468.8315  104154.2650  102104.710940  103860.863212  \n",
      "51220  1241.269510  101489.6140  104068.2322  102158.867041  103814.294067  \n",
      "51221  1451.582400  101583.1680  103972.2020  102237.633037  103781.808417  \n",
      "51222  1801.602230  101675.0840  103880.8700  102329.506081  103759.082597  \n",
      "51223   676.784880  101800.2860  103783.6300  102397.808359  103731.145240  \n",
      "\n",
      "[51224 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "df_BTC['SMA_20'] = calculate_SMA20(df_BTC)\n",
    "df_BTC['SMA_50'] = calculate_SMA50(df_BTC)\n",
    "\n",
    "df_BTC['EMA_20'] = calculate_EMA20(df_BTC)\n",
    "df_BTC['EMA_50'] = calculate_EMA50(df_BTC)\n",
    "\n",
    "print(df_BTC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2e0800",
   "metadata": {},
   "source": [
    "# Find Pivot Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b0c0938e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pivots(df: pd.DataFrame, window: int = 2, min_gap: int = 1) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Detect pivot (fractal) points in OHLC data, then thin so that in any\n",
    "    `min_gap` consecutive bars there is at most one pivot (of any type).\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: 0 = no pivot, 1 = pivot high, 2 = pivot low, 3 = both.\n",
    "    \"\"\"\n",
    "    pivots = [0] * len(df)\n",
    "\n",
    "    for candle in range(len(df)):\n",
    "        # skip edges\n",
    "        if candle - window < 0 or candle + window >= len(df):\n",
    "            continue\n",
    "\n",
    "        pivotHigh = True\n",
    "        pivotLow = True\n",
    "\n",
    "        # check neighborhood [candle-window, candle+window]\n",
    "        for i in range(candle - window, candle + window + 1):\n",
    "            if df.iloc[candle].low > df.iloc[i].low:\n",
    "                pivotLow = False\n",
    "            if df.iloc[candle].high < df.iloc[i].high:\n",
    "                pivotHigh = False\n",
    "\n",
    "        if pivotHigh and pivotLow:\n",
    "            pivots[candle] = 3\n",
    "        elif pivotHigh:\n",
    "            pivots[candle] = 1\n",
    "        elif pivotLow:\n",
    "            pivots[candle] = 2\n",
    "\n",
    "    # === Spacing enforcement: at most one pivot in any `min_gap` bars ===\n",
    "    # Treat any non-zero (1,2,3) as a pivot; keep the first, drop others within the next (min_gap-1) bars.\n",
    "    piv = np.array(pivots, dtype=int)\n",
    "    last_kept = -10**9  # sufficiently negative\n",
    "\n",
    "    # indices of any pivot (1,2,3), in chronological order\n",
    "    pivot_idx = np.where(piv != 0)[0]\n",
    "\n",
    "    for idx in pivot_idx:\n",
    "        if idx - last_kept >= min_gap:\n",
    "            last_kept = idx      # keep this pivot\n",
    "        else:\n",
    "            piv[idx] = 0         # too close to previous pivot → drop\n",
    "\n",
    "    return pd.Series(piv, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a7c40c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_BTC['isPivot'] = find_pivots(df_BTC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a348061e",
   "metadata": {},
   "source": [
    "# Finding Support/Resistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a013a081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _cluster_pivots_by_window(df: pd.DataFrame,\n",
    "                              idxs: np.ndarray,\n",
    "                              prices: pd.Series,\n",
    "                              window_bars: int = 20,\n",
    "                              min_points: int = 2) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Group pivot indices into clusters where max_index - first_index <= window_bars,\n",
    "    then take the mean price per cluster. Only keep clusters with >= min_points.\n",
    "    Returns a DataFrame with columns:\n",
    "      ['level','n_points','start_idx','end_idx','start_time','end_time']\n",
    "    \"\"\"\n",
    "    if len(idxs) == 0:\n",
    "        return pd.DataFrame(columns=['level','n_points','start_idx','end_idx','start_time','end_time'])\n",
    "\n",
    "    clusters = []\n",
    "    current = [(idxs[0], float(prices.loc[idxs[0]]))]\n",
    "    cluster_start = idxs[0]\n",
    "\n",
    "    for idx in idxs[1:]:\n",
    "        if idx - cluster_start <= window_bars:\n",
    "            current.append((idx, float(prices.loc[idx])))\n",
    "        else:\n",
    "            # finalize previous cluster\n",
    "            if len(current) >= min_points:\n",
    "                lvl = np.mean([p for _, p in current])\n",
    "                start_i, end_i = current[0][0], current[-1][0]\n",
    "                clusters.append({\n",
    "                    'level': lvl,\n",
    "                    'n_points': len(current),\n",
    "                    'start_idx': start_i,\n",
    "                    'end_idx': end_i,\n",
    "                    'start_time': df.loc[start_i, 'timestamp'] if 'timestamp' in df.columns else start_i,\n",
    "                    'end_time': df.loc[end_i, 'timestamp'] if 'timestamp' in df.columns else end_i,\n",
    "                })\n",
    "            # start a new cluster\n",
    "            current = [(idx, float(prices.loc[idx]))]\n",
    "            cluster_start = idx\n",
    "\n",
    "    # finalize last cluster\n",
    "    if len(current) >= min_points:\n",
    "        lvl = np.mean([p for _, p in current])\n",
    "        start_i, end_i = current[0][0], current[-1][0]\n",
    "        clusters.append({\n",
    "            'level': lvl,\n",
    "            'n_points': len(current),\n",
    "            'start_idx': start_i,\n",
    "            'end_idx': end_i,\n",
    "            'start_time': df.loc[start_i, 'timestamp'] if 'timestamp' in df.columns else start_i,\n",
    "            'end_time': df.loc[end_i, 'timestamp'] if 'timestamp' in df.columns else end_i,\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4e4dfa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sr_levels(df: pd.DataFrame,\n",
    "                      window_bars: int = 20,\n",
    "                      min_points: int = 2,\n",
    "                      include_both_as_both: bool = True):\n",
    "    \"\"\"\n",
    "    Build resistance/support by clustering nearby pivots and averaging their prices.\n",
    "    - window_bars: 'closeness' in bars (time). Use 20 per your spec.\n",
    "    - min_points: require at least this many pivots in the cluster (2+).\n",
    "    - include_both_as_both: treat '3' pivots as both high and low.\n",
    "    Returns: (resist_df, support_df)\n",
    "    \"\"\"\n",
    "    # pick which pivot codes count\n",
    "    res_codes = [1, 3] if include_both_as_both else [1]\n",
    "    sup_codes = [2, 3] if include_both_as_both else [2]\n",
    "\n",
    "    # indices of pivots\n",
    "    res_idxs = df.index[df['isPivot'].isin(res_codes)].to_numpy()\n",
    "    sup_idxs = df.index[df['isPivot'].isin(sup_codes)].to_numpy()\n",
    "\n",
    "    # prices to average\n",
    "    res_prices = df['high']\n",
    "    sup_prices = df['low']\n",
    "\n",
    "    resist_df = _cluster_pivots_by_window(df, res_idxs, res_prices, window_bars, min_points)\n",
    "    support_df = _cluster_pivots_by_window(df, sup_idxs, sup_prices, window_bars, min_points)\n",
    "\n",
    "    resist_df['kind'] = 'resistance'\n",
    "    support_df['kind'] = 'support'\n",
    "    return resist_df, support_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f653b0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         level  n_points  start_idx  end_idx          start_time  \\\n",
      "0  7243.500000         4          3       15 2020-01-01 03:00:00   \n",
      "1  7222.355000         2         34       52 2020-01-02 10:00:00   \n",
      "2  7375.240000         5         58       77 2020-01-03 10:00:00   \n",
      "3  7408.985000         4         82      100 2020-01-04 10:00:00   \n",
      "4  7508.153333         3        108      123 2020-01-05 12:00:00   \n",
      "\n",
      "             end_time        kind  \n",
      "0 2020-01-01 15:00:00  resistance  \n",
      "1 2020-01-03 04:00:00  resistance  \n",
      "2 2020-01-04 05:00:00  resistance  \n",
      "3 2020-01-05 04:00:00  resistance  \n",
      "4 2020-01-06 03:00:00  resistance  \n",
      "         level  n_points  start_idx  end_idx          start_time  \\\n",
      "0  7157.283333         3          8       28 2020-01-01 08:00:00   \n",
      "1  6989.896000         5         31       50 2020-01-02 07:00:00   \n",
      "2  7256.720000         3         62       73 2020-01-03 14:00:00   \n",
      "3  7323.027500         4         85      105 2020-01-04 13:00:00   \n",
      "4  7401.736667         3        114      133 2020-01-05 18:00:00   \n",
      "\n",
      "             end_time     kind  \n",
      "0 2020-01-02 04:00:00  support  \n",
      "1 2020-01-03 02:00:00  support  \n",
      "2 2020-01-04 01:00:00  support  \n",
      "3 2020-01-05 09:00:00  support  \n",
      "4 2020-01-06 13:00:00  support  \n"
     ]
    }
   ],
   "source": [
    "resist_df, support_df = compute_sr_levels(df_BTC, window_bars=20, min_points=2)\n",
    "print(resist_df.head())\n",
    "print(support_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93683ac3",
   "metadata": {},
   "source": [
    "# Plotting to Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "545524bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p8/by67wr7139zdvwbp6501h9lh0000gn/T/ipykernel_59888/2331346859.py:8: DeprecationWarning:\n",
      "\n",
      "is_datetime64tz_dtype is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.DatetimeTZDtype)` instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "\n",
    "# --- safety: ensure timestamp is tz-naive datetime ---\n",
    "if not pd.api.types.is_datetime64_any_dtype(df_BTC['timestamp']):\n",
    "    df_BTC['timestamp'] = pd.to_datetime(df_BTC['timestamp'], errors='coerce')\n",
    "if pd.api.types.is_datetime64tz_dtype(df_BTC['timestamp'].dtype):\n",
    "    df_BTC['timestamp'] = df_BTC['timestamp'].dt.tz_convert('UTC').dt.tz_localize(None)\n",
    "\n",
    "# --- safety: compute isPivot if missing (uses your previously defined find_pivots) ---\n",
    "if 'isPivot' not in df_BTC.columns:\n",
    "    df_BTC['isPivot'] = find_pivots(df_BTC, window=10, min_gap=4)\n",
    "\n",
    "# --- pivot markers (treat code 3 as both) ---\n",
    "df_BTC['pivot_high_price'] = np.where(df_BTC['isPivot'].isin([1,3]), df_BTC['high'] * 1.001, np.nan)\n",
    "df_BTC['pivot_low_price']  = np.where(df_BTC['isPivot'].isin([2,3]), df_BTC['low']  * 0.999, np.nan)\n",
    "\n",
    "# --- slice for plotting (same as your index slice) ---\n",
    "df_plot = (df_BTC[800:1000]\n",
    "           .dropna(subset=['timestamp', 'open', 'high', 'low', 'close'])\n",
    "           .sort_values('timestamp')\n",
    "           .reset_index(drop=True))\n",
    "\n",
    "# === SR level computation (cluster nearby pivots and take mean price) ===\n",
    "def compute_sr_levels(df: pd.DataFrame,\n",
    "                      window_bars: int = 20,\n",
    "                      min_points: int = 2,\n",
    "                      include_both_as_both: bool = True):\n",
    "    res_codes = [1, 3] if include_both_as_both else [1]\n",
    "    sup_codes = [2, 3] if include_both_as_both else [2]\n",
    "\n",
    "    res_idxs = df.index[df['isPivot'].isin(res_codes)].to_numpy()\n",
    "    sup_idxs = df.index[df['isPivot'].isin(sup_codes)].to_numpy()\n",
    "\n",
    "    res_prices = df['high']\n",
    "    sup_prices = df['low']\n",
    "\n",
    "    resist_df = _cluster_pivots_by_window(df, res_idxs, res_prices, window_bars, min_points)\n",
    "    support_df = _cluster_pivots_by_window(df, sup_idxs, sup_prices, window_bars, min_points)\n",
    "\n",
    "    resist_df['kind'] = 'resistance'\n",
    "    support_df['kind'] = 'support'\n",
    "    return resist_df, support_df\n",
    "\n",
    "# compute zones on full dataset, then only draw ones overlapping the plotted time window\n",
    "resist_df, support_df = compute_sr_levels(df_BTC, window_bars=20, min_points=2)\n",
    "\n",
    "t0, t1 = df_plot['timestamp'].min(), df_plot['timestamp'].max()\n",
    "def overlaps(row):\n",
    "    return not (row['end_time'] < t0 or row['start_time'] > t1)\n",
    "\n",
    "res_to_draw = resist_df[resist_df.apply(overlaps, axis=1)].reset_index(drop=True)\n",
    "sup_to_draw = support_df[support_df.apply(overlaps, axis=1)].reset_index(drop=True)\n",
    "\n",
    "# ------------------- Plot -------------------\n",
    "fig = go.Figure()\n",
    "\n",
    "# Candlesticks\n",
    "fig.add_trace(go.Candlestick(\n",
    "    x=df_plot['timestamp'],\n",
    "    open=df_plot['open'],\n",
    "    high=df_plot['high'],\n",
    "    low=df_plot['low'],\n",
    "    close=df_plot['close'],\n",
    "    name='BTC'\n",
    "))\n",
    "\n",
    "# Pivot highs (▲ red)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_plot['timestamp'],\n",
    "    y=df_plot['pivot_high_price'],\n",
    "    mode='markers',\n",
    "    name='Pivot High',\n",
    "    marker=dict(symbol='triangle-up', color='red', size=8),\n",
    "    hovertemplate=\"Pivot High<br>%{x|%Y-%m-%d %H:%M:%S}<br>Price: %{y:.2f}<extra></extra>\"\n",
    "))\n",
    "\n",
    "# Pivot lows (▼ green)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_plot['timestamp'],\n",
    "    y=df_plot['pivot_low_price'],\n",
    "    mode='markers',\n",
    "    name='Pivot Low',\n",
    "    marker=dict(symbol='triangle-down', color='lime', size=8),\n",
    "    hovertemplate=\"Pivot Low<br>%{x|%Y-%m-%d %H:%M:%S}<br>Price: %{y:.2f}<extra></extra>\"\n",
    "))\n",
    "\n",
    "# --- draw SR lines across the visible window (t0 -> t1) ---\n",
    "# Resistances\n",
    "for _, r in res_to_draw.iterrows():\n",
    "    fig.add_shape(\n",
    "        type=\"line\",\n",
    "        xref=\"x\", yref=\"y\",\n",
    "        x0=t0, x1=t1,\n",
    "        y0=r['level'], y1=r['level'],\n",
    "        line=dict(color=\"red\", dash=\"dot\", width=1),\n",
    "        opacity=0.8\n",
    "    )\n",
    "    fig.add_annotation(\n",
    "        x=t1, y=r['level'],\n",
    "        xref=\"x\", yref=\"y\",\n",
    "        text=f\"R ({int(r['n_points'])})\",\n",
    "        showarrow=False, xanchor=\"left\", yanchor=\"middle\",\n",
    "        font=dict(size=10, color=\"red\")\n",
    "    )\n",
    "\n",
    "# Supports\n",
    "for _, s in sup_to_draw.iterrows():\n",
    "    fig.add_shape(\n",
    "        type=\"line\",\n",
    "        xref=\"x\", yref=\"y\",\n",
    "        x0=t0, x1=t1,\n",
    "        y0=s['level'], y1=s['level'],\n",
    "        line=dict(color=\"green\", dash=\"dot\", width=1),\n",
    "        opacity=0.8\n",
    "    )\n",
    "    fig.add_annotation(\n",
    "        x=t1, y=s['level'],\n",
    "        xref=\"x\", yref=\"y\",\n",
    "        text=f\"S ({int(s['n_points'])})\",\n",
    "        showarrow=False, xanchor=\"left\", yanchor=\"middle\",\n",
    "        font=dict(size=10, color=\"green\")\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"BTC — Candlesticks, Pivots & Support/Resistance (window=10 pivots; SR cluster=20 bars)\",\n",
    "    xaxis_title=\"Time\",\n",
    "    yaxis_title=\"Price\",\n",
    "    xaxis_rangeslider_visible=False,\n",
    "    legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='left', x=0)\n",
    ")\n",
    "\n",
    "pio.renderers.default = \"browser\"\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544aea21",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1a81464",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e32ce056",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
